{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2441519c",
   "metadata": {},
   "source": [
    "# CusFlow - Exploration Notebook\n",
    "\n",
    "This notebook demonstrates the core capabilities of the CusFlow recommendation system.\n",
    "\n",
    "## Contents\n",
    "1. Data Generation\n",
    "2. Feature Engineering\n",
    "3. Model Training\n",
    "4. Evaluation & Metrics\n",
    "5. GenAI Features\n",
    "6. A/B Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# CusFlow imports\n",
    "from src.config import Domain, get_settings\n",
    "from src.data.loaders import SyntheticDataGenerator, DataLoader\n",
    "from src.ranking.lambdamart import LambdaMARTRanker\n",
    "from src.ranking.feature_engineering import FeatureEngineer\n",
    "from src.evaluation.metrics import RankingMetrics, ndcg_at_k\n",
    "\n",
    "print(\"CusFlow loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242cf1a1",
   "metadata": {},
   "source": [
    "## 1. Data Generation\n",
    "\n",
    "Generate synthetic data for hotels, wealth reports, or e-commerce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b11c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate hotel data\n",
    "generator = SyntheticDataGenerator(domain=Domain.HOTEL, seed=42)\n",
    "\n",
    "items = generator.generate_items(n_items=500)\n",
    "users = generator.generate_users(n_users=200)\n",
    "events = generator.generate_events(users, items, n_events=5000)\n",
    "\n",
    "print(f\"Generated {len(items)} items, {len(users)} users, {len(events)} events\")\n",
    "\n",
    "# Inspect sample item\n",
    "sample_item = items[0]\n",
    "print(f\"\\nSample Item:\")\n",
    "print(f\"  ID: {sample_item.item_id}\")\n",
    "print(f\"  Name: {sample_item.name}\")\n",
    "print(f\"  Features: {sample_item.features.features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19312f0d",
   "metadata": {},
   "source": [
    "## 2. Model Training\n",
    "\n",
    "Train a LambdaMART ranking model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training examples\n",
    "from collections import Counter\n",
    "\n",
    "training_examples = list(generator.generate_training_data(users, items, events))\n",
    "print(f\"Generated {len(training_examples)} training examples\")\n",
    "\n",
    "# Convert to arrays\n",
    "X = np.array([ex.features for ex in training_examples])\n",
    "y = np.array([ex.relevance for ex in training_examples])\n",
    "query_ids = [ex.query_id for ex in training_examples]\n",
    "query_counts = Counter(query_ids)\n",
    "groups = np.array([query_counts[qid] for qid in sorted(set(query_ids), key=query_ids.index)])\n",
    "\n",
    "# Split data\n",
    "n_train = int(len(groups) * 0.8)\n",
    "train_size = sum(groups[:n_train])\n",
    "X_train, X_val = X[:train_size], X[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]\n",
    "groups_train, groups_val = groups[:n_train], groups[n_train:]\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]} samples, {len(groups_train)} queries\")\n",
    "print(f\"Validation: {X_val.shape[0]} samples, {len(groups_val)} queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LambdaMART\n",
    "model = LambdaMARTRanker(num_boost_round=100, early_stopping_rounds=20)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, groups_train,\n",
    "    X_val=X_val, y_val=y_val, groups_val=groups_val,\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 Feature Importance:\")\n",
    "for name, score in list(model.get_feature_importance(top_k=10).items())[:10]:\n",
    "    print(f\"  {name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ceb640",
   "metadata": {},
   "source": [
    "## 3. Evaluation\n",
    "\n",
    "Evaluate the model with standard ranking metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a6f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "metrics = RankingMetrics(cutoffs=[5, 10, 20])\n",
    "results = metrics.evaluate(y_val, y_pred, groups_val)\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(\"-\" * 30)\n",
    "for metric, value in sorted(results.items()):\n",
    "    print(f\"{metric:15s}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae344040",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Synthetic data generation for hotel recommendations\n",
    "- LambdaMART model training\n",
    "- Offline evaluation with NDCG, MAP, Recall\n",
    "\n",
    "For more:\n",
    "- See `scripts/train_model.py` for production training\n",
    "- See `scripts/run_ab_sim.py` for A/B simulation\n",
    "- Run `python -m src.cli serve` for the API"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
